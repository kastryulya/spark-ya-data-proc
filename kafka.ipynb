{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39cc8239-8676-4e47-8b28-91215bc1cbbf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-13T04:53:02.609633Z",
     "iopub.status.busy": "2026-02-13T04:53:02.608438Z",
     "iopub.status.idle": "2026-02-13T04:53:02.714395Z",
     "shell.execute_reply": "2026-02-13T04:53:02.713149Z",
     "shell.execute_reply.started": "2026-02-13T04:53:02.609570Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lala\n"
     ]
    }
   ],
   "source": [
    "print('lala')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38679558-fe1d-4f68-81e6-a69bf7c0fe71",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T11:22:09.300026Z",
     "iopub.status.busy": "2026-02-12T11:22:09.298533Z",
     "iopub.status.idle": "2026-02-12T11:22:09.520699Z",
     "shell.execute_reply": "2026-02-12T11:22:09.519334Z",
     "shell.execute_reply.started": "2026-02-12T11:22:09.299956Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Certificate was added to keystore\n"
     ]
    }
   ],
   "source": [
    "# Подкачка сертификата на экзекьюторы при помощи команды curl\n",
    "import os\n",
    "# 0. Определение вспомогательных переменных — имени сертификата и его пароля\n",
    "ts_name = \"...\"\n",
    "ts_password = \"...\"\n",
    "\n",
    "# 1. Определение исполняемой команды curl для получения сертификата по указанному адресу\n",
    "certs = f\"curl -vs https://storage.yandexcloud.net/cloud-certs/CA.pem 2>/dev/null | keytool -importcert -alias YandexCA -keystore {ts_name} -storepass {ts_password} -noprompt\"\n",
    "\n",
    "# 2. Выполнение её внутри ОС виртуальных машин\n",
    "os.system(certs)\n",
    "\n",
    "# 3. Добавление созданного файла с сертификатом внутрь Spark. Это позволит экзекьюторам обращаться к файлу во время работы\n",
    "spark.sparkContext.addFile(ts_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b0a393-3977-4524-afa2-8607ff61408b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T11:36:12.662172Z",
     "iopub.status.busy": "2026-02-12T11:36:12.661181Z",
     "iopub.status.idle": "2026-02-12T11:36:12.687534Z",
     "shell.execute_reply": "2026-02-12T11:36:12.686293Z",
     "shell.execute_reply.started": "2026-02-12T11:36:12.662120Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Указание имени и пароля для пользователя, которые задавали в предыдущем уроке при создании Kafka-топика.\n",
    "user = \"...\"\n",
    "password = \"...\"\n",
    "# Указание адреса Kafka-брокера и имени топика Kafka, которые задавали в предыдущем уроке при создании Kafka-топика.\n",
    "# Не забудьте добавить номер порта :9091 в конце адреса kafka_broker!\n",
    "kafka_broker = \"...\"\n",
    "kafka_topic = \"...\"\n",
    "\n",
    "# Определение шаблона для JAAS-конфига, который будет нужен для аутентификации клиента Spark при подключении к Kafka\n",
    "jaas_conf_template = \"org.apache.kafka.common.security.scram.ScramLoginModule required username='{}' password='{}';\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6c1e3e31-c283-4319-ad16-578e25e29f32",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T11:37:19.837972Z",
     "iopub.status.busy": "2026-02-12T11:37:19.836784Z",
     "iopub.status.idle": "2026-02-12T11:37:28.342490Z",
     "shell.execute_reply": "2026-02-12T11:37:28.340897Z",
     "shell.execute_reply.started": "2026-02-12T11:37:19.837920Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|key |value                                                                                                                                                                                                |\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|null|{\"HOUSEHOLD_KEY\":3,\"BASKET_ID\":0,\"DAY\":1,\"PRODUCT_ID\":2,\"QUANTITY\":8,\"SALES_VALUE\":7.25,\"STORE_ID\":1,\"COUPON_MATCH_DISC\":13.89,\"COUPON_DISC\":30.85,\"RETAIL_DISC\":60.14,\"TRANS_TIME\":0,\"WEEK_NO\":1}   |\n",
      "|null|{\"HOUSEHOLD_KEY\":3,\"BASKET_ID\":1,\"DAY\":1,\"PRODUCT_ID\":1,\"QUANTITY\":2,\"SALES_VALUE\":7.52,\"STORE_ID\":2,\"COUPON_MATCH_DISC\":16.67,\"COUPON_DISC\":34.18,\"RETAIL_DISC\":63.06,\"TRANS_TIME\":400,\"WEEK_NO\":1} |\n",
      "|null|{\"HOUSEHOLD_KEY\":1,\"BASKET_ID\":2,\"DAY\":1,\"PRODUCT_ID\":2,\"QUANTITY\":5,\"SALES_VALUE\":7.99,\"STORE_ID\":1,\"COUPON_MATCH_DISC\":14.83,\"COUPON_DISC\":31.36,\"RETAIL_DISC\":67.8,\"TRANS_TIME\":800,\"WEEK_NO\":1}  |\n",
      "|null|{\"HOUSEHOLD_KEY\":2,\"BASKET_ID\":3,\"DAY\":1,\"PRODUCT_ID\":3,\"QUANTITY\":7,\"SALES_VALUE\":6.81,\"STORE_ID\":1,\"COUPON_MATCH_DISC\":18.42,\"COUPON_DISC\":42.68,\"RETAIL_DISC\":59.61,\"TRANS_TIME\":1200,\"WEEK_NO\":1}|\n",
      "|null|{\"HOUSEHOLD_KEY\":2,\"BASKET_ID\":4,\"DAY\":1,\"PRODUCT_ID\":1,\"QUANTITY\":8,\"SALES_VALUE\":8.56,\"STORE_ID\":2,\"COUPON_MATCH_DISC\":12.13,\"COUPON_DISC\":49.36,\"RETAIL_DISC\":58.46,\"TRANS_TIME\":1600,\"WEEK_NO\":1}|\n",
      "+----+-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kafka_df = spark \\\n",
    "  .read \\\n",
    "  .format(\"kafka\") \\\n",
    "  .option(\"kafka.bootstrap.servers\", kafka_broker) \\\n",
    "  .option(\"kafka.security.protocol\", \"SASL_SSL\") \\\n",
    "  .option(\"kafka.sasl.mechanism\", \"SCRAM-SHA-512\") \\\n",
    "  .option(\"kafka.ssl.truststore.location\",ts_name) \\\n",
    "  .option(\"kafka.ssl.truststore.password\",ts_password) \\\n",
    "  .option(\"kafka.sasl.jaas.config\", jaas_conf_template.format(user,password)) \\\n",
    "  .option(\"subscribe\", kafka_topic) \\\n",
    "  .option(\"includeHeaders\", \"true\") \\\n",
    "  .option(\"startingOffsets\", \"earliest\") \\\n",
    "  .load() \\\n",
    "  .selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\")\n",
    "\n",
    "kafka_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b05ed572-351c-4bda-9065-6fc2b8e9dc2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:28:31.048809Z",
     "iopub.status.busy": "2026-02-12T12:28:31.047713Z",
     "iopub.status.idle": "2026-02-12T12:28:46.246745Z",
     "shell.execute_reply": "2026-02-12T12:28:46.245554Z",
     "shell.execute_reply.started": "2026-02-12T12:28:31.048753Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/02/12 12:28:37 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 4:=====================================================>   (47 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2097686|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) from module_4.transactional_data_1').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c371c2c-f816-49c0-8bdf-d47ae238a9a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-12T12:35:18.404328Z",
     "iopub.status.busy": "2026-02-12T12:35:18.403169Z",
     "iopub.status.idle": "2026-02-12T12:35:19.716112Z",
     "shell.execute_reply": "2026-02-12T12:35:19.714673Z",
     "shell.execute_reply.started": "2026-02-12T12:35:18.404270Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:============================================>            (39 + 1) / 50]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "| 2097686|\n",
      "+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.sql('select count(*) from module_4.transactional_data_1').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
